{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHP5VOu0oiCD"
   },
   "source": [
    "# 0 Preparación del entorno.\n",
    "\n",
    "## 0.1 Definición de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "xussTphZSYVz"
   },
   "outputs": [],
   "source": [
    "tfm_path='C:/Users/raqga/OneDrive - Universidad Complutense de Madrid (UCM)/Documentos/tsa4dst/TFM_data/'\n",
    "H1_code = 'OMNI2_H0_MRG1HR'\n",
    "M5_code = 'OMNI_HRO2_5MIN'\n",
    "lookback = 12\n",
    "lookforward = 4\n",
    "tfm_path_Nh_models = f'PRED_{lookforward}h/'\n",
    "cols_to_use = ['Bx', 'By_gse', 'Bz_gse', 'By_gsm', 'Bz_gsm', 'P_density', 'E_field', 'plasma_T', 'plasma_V', 'Dst'] # 'AP', out\n",
    "col_to_predict = \"Dst\"\n",
    "hstorms_data = 'historical_storms_gruet2018.csv'\n",
    "weak_threshold = -30 #1\n",
    "moderate_threshold = -50 #2\n",
    "strong_threshold = -100 #3\n",
    "severe_threshold = -200 #4\n",
    "great_threshold = -300 #5\n",
    "gamma_value=0.0001\n",
    "temporal_margin=5*24 # margen para obtener tiempos ampliados de las tormentas de gruet et al 2018\n",
    "test_size = 0.2\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTnEx3feo7e4"
   },
   "source": [
    "## 0.2 Montar Google Drive (obtención de datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "n2tXbl93Tndp"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !rm -rf sample_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNzRT2z-o-ps"
   },
   "source": [
    "## 0.3 Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32213,
     "status": "ok",
     "timestamp": 1719831629912,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "OJtQv_kvy3ky",
    "outputId": "23d7858f-5abc-4373-fdb2-42842871bbe0"
   },
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "executionInfo": {
     "elapsed": 3792,
     "status": "ok",
     "timestamp": 1719831633701,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "sJuDqU5SzL4m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# librerías de manipulación de datos y gráficos\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "# gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# modelo\n",
    "from sklearn.svm import SVR\n",
    "#from thundersvm import SVR\n",
    "# escalado y división en train/test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# obtención de métricas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_log_error, median_absolute_error\n",
    "from sklearn.metrics import explained_variance_score, max_error\n",
    "\n",
    "# meta\n",
    "# timer\n",
    "import time\n",
    "\n",
    "#optuna\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719831633702,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "5zz1d21Fp6sn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cUAiVDJpFBD"
   },
   "source": [
    "## 0.4 Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719831633702,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "MKGLdDwbtVg3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def exploracion_inicial_datos(df):\n",
    "    \"\"\"\n",
    "    Función para realizar una exploración inicial de los datos.\n",
    "\n",
    "    Parámetros:\n",
    "    df (dataframe): El dataframe que contiene los datos.\n",
    "\n",
    "    Muestra las primeras filas, estadísticas descriptivas, valores faltantes,\n",
    "    histogramas de variables numéricas y un mapa de calor de la correlación.\n",
    "    \"\"\"\n",
    "    # Configuración de visualización\n",
    "    sns.set(style=\"whitegrid\")  # Estilo de gráficos\n",
    "\n",
    "\n",
    "    print(\"Primeras filas del DataFrame:\")\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "    print(\"\\nDescripción estadística de los datos:\")\n",
    "    print(df.describe())\n",
    "\n",
    "\n",
    "    print(\"\\nValores faltantes por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "\n",
    "    print(\"\\nVisualización de histogramas para variables numéricas:\")\n",
    "    df.hist(bins=15, figsize=(15, 10), layout=(5, 4))\n",
    "    plt.show()\n",
    "    print(\"\\nMapa de calor de la matriz de correlación:\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calcular_layout_optimo(num_cols):\n",
    "    \"\"\"\n",
    "    Calcula el número óptimo de filas y columnas para una figura con subgráficos,\n",
    "    tratando de mantener una forma que sea visualmente agradable y que aproveche el espacio.\n",
    "\n",
    "    Parámetros:\n",
    "    num_cols (int): Número total de columnas (gráficos) a mostrar.\n",
    "\n",
    "    Retorna:\n",
    "    (int, int): Número de filas y columnas para el layout de los subgráficos.\n",
    "    \"\"\"\n",
    "    # Calcula el número óptimo de columnas teniendo un límite visual razonable\n",
    "    cols_per_row = int(np.sqrt(num_cols)) + 1  # Ajuste para maximizar el uso del espacio y la forma de la figura\n",
    "    rows_needed = (num_cols + cols_per_row - 1) // cols_per_row  # Redondeo hacia arriba para incluir todas las columnas\n",
    "    return rows_needed, cols_per_row\n",
    "\n",
    "def exploracion_histogramas(df):\n",
    "    \"\"\"\n",
    "    Función para generar histogramas para todas las columnas numéricas en un DataFrame,\n",
    "    excluyendo las columnas de tipo datetime y no numéricas.\n",
    "\n",
    "    Parámetros:\n",
    "    df (DataFrame): DataFrame de pandas con los datos a analizar.\n",
    "    \"\"\"\n",
    "    # Eliminar columnas no numéricas y de tipo datetime\n",
    "    df_numerico = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Número de columnas numéricas\n",
    "    num_cols = df_numerico.shape[1]\n",
    "\n",
    "    # Verificar si hay columnas para mostrar\n",
    "    if num_cols == 0:\n",
    "        print(\"No hay columnas numéricas para mostrar.\")\n",
    "        return\n",
    "\n",
    "    # Calculando el layout necesario\n",
    "    rows_needed, cols_per_row = calcular_layout_optimo(num_cols)\n",
    "\n",
    "    # Crear histogramas\n",
    "    df_numerico.hist(bins=15, figsize=(15, 10), layout=(rows_needed, cols_per_row))\n",
    "    plt.show()\n",
    "\n",
    "def imputar_nan(df):\n",
    "  df.interpolate(method='linear', inplace=True)\n",
    "  df.fillna(method='ffill', inplace=True)\n",
    "  df.fillna(method='bfill', inplace=True)\n",
    "  if sum(df.isnull().sum())!=0:\n",
    "    print(\"Faltan nulos por tratar\")\n",
    "  return df\n",
    "\n",
    "def visualizar_nulos_plot(df, variable_with_nans):\n",
    "    \"\"\"\n",
    "    Plot the specified 'variable_with_nans' column and 'Dst' column from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data to plot.\n",
    "    - variable_with_nans: str, the name of the column in the DataFrame to plot, which may contain NaNs.\n",
    "\n",
    "    The function assumes that 'Dst' is a column name in the DataFrame and that the DataFrame's index is suitable for plotting (e.g., datetime).\n",
    "    \"\"\"\n",
    "    # Create the figure and subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(20, 8))\n",
    "\n",
    "    # Handling NaNs in the 'variable_with_nans' column before plotting\n",
    "    df_plot = df.copy()\n",
    "    df_plot[variable_with_nans] = df_plot[variable_with_nans].fillna(method='ffill')  # Forward fill to handle NaNs\n",
    "\n",
    "    # Plotting 'variable_with_nans' on the first subplot\n",
    "    ax1.scatter(df_plot.index, df_plot[variable_with_nans], label=variable_with_nans, color='blue')\n",
    "    ax1.set_ylabel(variable_with_nans)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plotting 'Dst' on the second subplot\n",
    "    ax2.plot(df_plot.index, df_plot['Dst'], label='Dst', color='red')\n",
    "    ax2.set_ylabel('Dst')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Setting the x-axis label only on the bottom subplot\n",
    "    ax2.set_xlabel('Datetime')\n",
    "\n",
    "    # Improve layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example of how to use this function with a DataFrame containing NaNs\n",
    "data = {\n",
    "    'Datetime': pd.date_range(start='2021-01-01', periods=100, freq='D'),\n",
    "    'variable_with_nans': pd.Series(range(100)).where(lambda x : x % 10 != 0),\n",
    "    'Dst': range(100, 0, -1)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('Datetime', inplace=True)\n",
    "\n",
    "def create_window_df_svr(list_dfs, lookback, lookforward, cols_to_use, col_to_predict, scaler_label=None):\n",
    "    \"\"\"\n",
    "    Creates input and output datasets for SVR training from a list of DataFrames, incorporating windowing and optional descaling for target\n",
    "\n",
    "    Parameters:\n",
    "    list_dfs (list of pandas.DataFrame): List of DataFrames to process.\n",
    "    lookback (int): Number of past records to include as features for each prediction.\n",
    "    lookforward (int): Number of records ahead to predict.\n",
    "    cols_to_use (list of str): List of column names to use as features.\n",
    "    col_to_predict (str): Column name to predict.\n",
    "    scaler_label (StandardScaler, optional): Scaler for the output variable, used for inverse transformation.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing arrays for training features and labels.\n",
    "    \"\"\"\n",
    "    x_train, y_train = [], []\n",
    "\n",
    "    for df_ in list_dfs:\n",
    "        df = df_.copy()\n",
    "\n",
    "        for i in range(len(df) - lookback - lookforward + 1):\n",
    "            x_train.append(np.asarray(df.iloc[i:i+lookback][cols_to_use].values))\n",
    "            y_train.append(np.asarray(df.iloc[i+lookback][col_to_predict]))\n",
    "\n",
    "    if scaler_label is not None:\n",
    "        y_train = scaler_label.inverse_transform(np.asarray(y_train).reshape(-1,1))\n",
    "\n",
    "    return np.asarray(x_train), np.asarray(y_train)\n",
    "\n",
    "\n",
    "def filter_storms(df, historical_storms, temporal_margin):\n",
    "    \"\"\"\n",
    "    Filter DataFrame entries based on the occurrence of storms within specific time intervals.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing time-series data with a 'Datetime' column.\n",
    "    historical_storms (pandas.DataFrame): DataFrame containing the start and end times of historical storms.\n",
    "    temporal_margin (int): Number of rows before and after the minimum Dst index to include in the result.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of DataFrame snippets corresponding to the specified storm intervals.\n",
    "    \"\"\"\n",
    "    all_storms = []\n",
    "    for i in range(len(historical_storms)):\n",
    "        df_tmp = df[(df[\"Datetime\"] >= historical_storms.iloc[i][\"start\"]) & (df[\"Datetime\"] <= historical_storms.iloc[i][\"end\"])]\n",
    "        idx = df_tmp['Dst'].idxmin()\n",
    "        all_storms.append(df.iloc[idx-temporal_margin:idx+temporal_margin])\n",
    "    return all_storms\n",
    "\n",
    "def combinar_dataframes_solapados(dfs):\n",
    "    \"\"\"\n",
    "    Combines overlapping DataFrames in a list into non-overlapping DataFrames based on the 'Datetime' column.\n",
    "\n",
    "    Parameters:\n",
    "    dfs (list of pandas.DataFrame): List of DataFrames to combine.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of combined DataFrames without overlap.\n",
    "    \"\"\"\n",
    "    dfs.sort(key=lambda x: x['Datetime'].min())\n",
    "    combinados = []\n",
    "    combinacion_actual = dfs[0]\n",
    "\n",
    "    for df in dfs[1:]:\n",
    "        if df['Datetime'].min() <= combinacion_actual['Datetime'].max():\n",
    "            combinacion_actual = pd.concat([combinacion_actual, df]).drop_duplicates().sort_values(by='Datetime')\n",
    "        else:\n",
    "            combinados.append(combinacion_actual)\n",
    "            combinacion_actual = df\n",
    "    combinados.append(combinacion_actual)\n",
    "    return combinados\n",
    "\n",
    "def scale_data(list_dfs, cols_to_use, col_to_predict):\n",
    "    \"\"\"\n",
    "    Scales columns in a list of DataFrames using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    list_dfs (list of pandas.DataFrame): List of DataFrames to scale.\n",
    "    cols_to_use (list of str): Column names to apply scaling to.\n",
    "    col_to_predict (str): Column name used as a label for prediction.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the list of scaled DataFrames and the label scaler.\n",
    "    \"\"\"\n",
    "    list_dfs_ = []\n",
    "    scaler_cols = StandardScaler()\n",
    "    scaler_label = StandardScaler()\n",
    "    scaler_cols.fit(pd.concat(list_dfs)[cols_to_use])\n",
    "    scaler_label.fit(np.asarray(pd.concat(list_dfs)[col_to_predict]).reshape(-1,1))\n",
    "\n",
    "    for df_ in list_dfs:\n",
    "        df = df_.copy()\n",
    "        df[cols_to_use] = scaler_cols.transform(df[cols_to_use])\n",
    "        list_dfs_.append(df)\n",
    "\n",
    "    return list_dfs_, scaler_label\n",
    "\n",
    "\n",
    "\n",
    "def calc_metrics(predictions, y_test):\n",
    "  # Mean Squared Error\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  # Mean Absolute Error\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  # R^2 Score, the coefficient of determination\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "  # Median Absolute Error\n",
    "  medae = median_absolute_error(y_test, predictions)\n",
    "  # Explained Variance Score\n",
    "  explained_variance = explained_variance_score(y_test, predictions)\n",
    "  # Max Error\n",
    "  max_err = max_error(y_test, predictions)\n",
    "\n",
    "  return mse, mae, r2, medae, explained_variance, max_err\n",
    "\n",
    "\n",
    "def formatear_tiempo(segundos):\n",
    "    horas = int(segundos // 3600)\n",
    "    minutos = int((segundos % 3600) // 60)\n",
    "    segundos = segundos % 60\n",
    "    return f\"{horas} horas, {minutos} minutos, {segundos:.2f} segundos\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1719831633702,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "dhsyk8pnCibA"
   },
   "outputs": [],
   "source": [
    "def evaluate_svr_models(X_train, y_train, X_test, y_test, kernels, C_values, epsilon_values, gamma_values, degree_values, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate SVR models with different hyperparameter configurations and kernel types.\n",
    "\n",
    "    Args:\n",
    "    X_train (array): Independent training data.\n",
    "    y_train (array): Dependent training data (target).\n",
    "    X_test (array): Independent test data.\n",
    "    y_test (array): Dependent test data (target).\n",
    "    kernels (list): List of kernel types to evaluate.\n",
    "    C_values (list): List of values for the penalty parameter C.\n",
    "    epsilon_values (list): List of values for the epsilon parameter.\n",
    "    gamma_values (list): List of values for the gamma parameter.\n",
    "    degree_values (list): List of values for the degree parameter (used only in polynomial kernels).\n",
    "    verbose (bool, optional): If True, prints messages during the evaluation process. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame containing evaluation metrics for each parameter configuration.\n",
    "    dict: A dictionary of trained models, with keys describing the specific parameter configuration.\n",
    "\n",
    "    Note:\n",
    "    Assumes that the 'precomputed' kernel is only used if the 'precomputed_matrix' is defined in the local environment.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    models_dict = {}\n",
    "\n",
    "    for kernel_ in kernels:\n",
    "        for C in C_values:\n",
    "            for epsilon in epsilon_values:\n",
    "                # Check parameter relevance for gamma and degree for the current kernel\n",
    "                relevant_gamma_values = gamma_values if kernel_ in ['rbf', 'sigmoid', 'poly'] else [None]\n",
    "                relevant_degree_values = degree_values if kernel_ == 'poly' else [None]\n",
    "\n",
    "                for gamma in relevant_gamma_values:\n",
    "                    for degree in relevant_degree_values:\n",
    "                        start = time.time()\n",
    "                        config_key = f\"{kernel_}_C{C}_eps{epsilon}_gamma{gamma}_deg{degree}\"\n",
    "                        if verbose:\n",
    "                            print(f\"Starting {config_key}\")\n",
    "\n",
    "                        if kernel_ == \"precomputed\":\n",
    "                            if 'precomputed_matrix' in locals():\n",
    "                                model = SVR(kernel='precomputed', C=C, epsilon=epsilon)\n",
    "                                model.fit(precomputed_matrix, y_train)\n",
    "                                models_dict[config_key] = model\n",
    "                                continue\n",
    "                            else:\n",
    "                                if verbose:\n",
    "                                    print(\"Precomputed matrix not defined for kernel='precomputed'\")\n",
    "                                continue\n",
    "\n",
    "                        model = SVR(kernel=kernel_, C=C, epsilon=epsilon, gamma=(gamma if gamma is not None else 0.01), degree=(degree if degree is not None else 3))\n",
    "                        model.fit(X_train, y_train)\n",
    "                        models_dict[config_key] = model\n",
    "\n",
    "                        predictions = model.predict(X_test)\n",
    "                        mse, mae, r2, medae, explained_variance, max_err = calc_metrics(predictions, y_test)\n",
    "                        end = time.time()\n",
    "                        time_exec = formatear_tiempo(end - start)\n",
    "\n",
    "                        results.append({\n",
    "                            \"kernel\": kernel_,\n",
    "                            \"C\": C,\n",
    "                            \"epsilon\": epsilon,\n",
    "                            \"gamma\": gamma,\n",
    "                            \"degree\": degree,\n",
    "                            \"mse\": mse,\n",
    "                            \"mae\": mae,\n",
    "                            \"r2\": r2,\n",
    "                            \"medae\": medae,\n",
    "                            \"exp_var\": explained_variance,\n",
    "                            \"max_err\": max_err,\n",
    "                            \"time_exec\": time_exec\n",
    "                        })\n",
    "\n",
    "                        print(f\"{config_key} finished. Time for iteration: {time_exec} | mae: {mae} | mse: {mse} | exp_var: {explained_variance} | max_err: {max_err}\")\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results, models_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiZeUiNVpNrd"
   },
   "source": [
    "# 1. Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kt5CN8t9pnMA"
   },
   "source": [
    "## 1.1 Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1719831634956,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "o0zK7ahApmQf"
   },
   "outputs": [],
   "source": [
    "hd = pd.read_csv(tfm_path+H1_code+'.csv', parse_dates=[\"Datetime\"])\n",
    "# md = pd.read_csv(tfm_path+M5_code+'.csv', parse_dates=[\"Datetime\"]) # no se va a usar por ahora\n",
    "historical_storms = pd.read_csv(tfm_path+hstorms_data)\n",
    "# historical_storms = historical_storms.drop(columns=['Min. Dst (nT)','Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4mHmDLrtEKs"
   },
   "source": [
    "- Ver qué columnas y tipo de datos contienen los df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "up24FqxwscRS",
    "outputId": "536f508f-4b13-4eb8-b18f-af4d7001a4de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_IMF', 'ID_plasma', 'Bmag', 'dev_Bmag', 'Bx', 'By_gse', 'Bz_gse',\n",
       "       'By_gsm', 'Bz_gsm', 'dev_Bx', 'dev_By', 'dev_Bz', 'P_density',\n",
       "       'dev_P_density', 'AP', 'dev_AP', 'E_field', 'plasma_T', 'dev_plasma_T',\n",
       "       'plasma_V', 'Dst', 'Datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "f3lGenT5tId9",
    "outputId": "0e19c4e4-17da-4544-b3ed-7ffb13dd3881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_IMF                  float64\n",
       "ID_plasma               float64\n",
       "Bmag                    float64\n",
       "dev_Bmag                float64\n",
       "Bx                      float64\n",
       "By_gse                  float64\n",
       "Bz_gse                  float64\n",
       "By_gsm                  float64\n",
       "Bz_gsm                  float64\n",
       "dev_Bx                  float64\n",
       "dev_By                  float64\n",
       "dev_Bz                  float64\n",
       "P_density               float64\n",
       "dev_P_density           float64\n",
       "AP                      float64\n",
       "dev_AP                  float64\n",
       "E_field                 float64\n",
       "plasma_T                float64\n",
       "dev_plasma_T            float64\n",
       "plasma_V                float64\n",
       "Dst                     float64\n",
       "Datetime         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "2s-_PYArsgz4",
    "outputId": "69ea9159-795b-4dc6-dc10-fd17097b45ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Min. Dst (nT)', 'start', 'end', 'storm'], dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_storms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "oq6T4hJDsm3Q",
    "outputId": "53c5b60c-976a-499b-c55c-560ba4585a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "Min. Dst (nT)     int64\n",
       "start            object\n",
       "end              object\n",
       "storm             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_storms.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyL09t1Ks9jW"
   },
   "source": [
    "- Ordenar las tormentas en caso de que no lo estén\n",
    "- Convertir todas las fechas a datetime de pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "KKh0YUUIq6xc"
   },
   "outputs": [],
   "source": [
    "# Ordenar los dataframes por fecha\n",
    "historical_storms = historical_storms.sort_values(by='start')\n",
    "\n",
    "# convertir las columnas de tiempo a datetime64\n",
    "hd['Datetime']=pd.to_datetime(hd['Datetime'])\n",
    "historical_storms['start']=pd.to_datetime(historical_storms['start'])\n",
    "historical_storms['end']=pd.to_datetime(historical_storms['end'])\n",
    "\n",
    "# Cuando se utilizan los datos a 5 minutos, se unen a 5min\n",
    "#data = pd.merge(md, hd[[\"Datetime\", \"Dst\"]], on='Datetime', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzCZp1Ndpt_F"
   },
   "source": [
    "## 1.2 Exploración inicial de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sngrxbi1uXRA"
   },
   "source": [
    "- head del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "lavp1YMbuOQZ"
   },
   "outputs": [],
   "source": [
    "# hd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVAqYfC9uU3P"
   },
   "source": [
    "- descripción estadística de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "t0-OstdCuSlD"
   },
   "outputs": [],
   "source": [
    "# hd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Ry8TktulyE"
   },
   "source": [
    "- ver los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "xnw_H2T-ulg5"
   },
   "outputs": [],
   "source": [
    "# hd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "d-LN6q6fuixi"
   },
   "outputs": [],
   "source": [
    "# hd.isnull().sum() / len(hd) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx6zks84uzv8"
   },
   "source": [
    "- Histograma para variables numéricas (todas, en este caso, pero hemos quitado datetime porque no es muy util al ser una serie temporal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634957,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "ke7ogtCzu0KB"
   },
   "outputs": [],
   "source": [
    "# exploracion_histogramas(hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkDpVZ15xPMM"
   },
   "source": [
    "- Visualizaciónd e historical_storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831634958,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "Vr2COnTg0D6S"
   },
   "outputs": [],
   "source": [
    "# storms_data = historical_storms.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634958,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "4ivSRmTdz-Kf"
   },
   "outputs": [],
   "source": [
    "# # Convertir las columnas de fecha y hora a datetime\n",
    "# storms_data['start'] = pd.to_datetime(storms_data['start'])\n",
    "# storms_data['end'] = pd.to_datetime(storms_data['end'])\n",
    "# # Calcular la duración de cada tormenta en horas\n",
    "# storms_data['duration_hours'] = (storms_data['end'] - storms_data['start']).dt.total_seconds() / 3600\n",
    "\n",
    "# # Gráfico de la distribución de las intensidades mínimas de las tormentas\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# sns.histplot(storms_data['Min. Dst (nT)'], bins=30, kde=True, color='blue')\n",
    "# plt.title('Distribución de Intensidades Mínimas de Tormentas Geomagnéticas')\n",
    "# plt.xlabel('Min. Dst (nT)')\n",
    "# plt.ylabel('Frecuencia')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnkxO8Zk0pnw"
   },
   "source": [
    "Gráfico de dispersión entre la duración y la intensidad mínima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634958,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "hCSpRC9N0i8E"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(x='duration_hours', y='Min. Dst (nT)', data=storms_data)\n",
    "# plt.title('Correlación entre Duración e Intensidad Mínima de Tormentas')\n",
    "# plt.xlabel('Duración (Horas)')\n",
    "# plt.ylabel('Min. Dst (nT)')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2tC7isT0yJI"
   },
   "source": [
    "- Ver el timeline de las tormentas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634958,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "KfIV8r9Q00gx"
   },
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "\n",
    "# # Crear la figura\n",
    "# fig = go.Figure()\n",
    "\n",
    "# # Añadir cada tormenta como un segmento de línea en el gráfico\n",
    "# for i, row in storms_data.iterrows():\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=[row['start'], row['end']],\n",
    "#         y=[i, i],\n",
    "#         mode='lines+markers',\n",
    "#         name=f\"Tormenta {row['storm']}\"\n",
    "#     ))\n",
    "\n",
    "# # Ajustar la presentación de la figura\n",
    "# fig.update_layout(\n",
    "#     title=\"Línea de Tiempo de Tormentas Históricas\",\n",
    "#     xaxis_title=\"Fecha\",\n",
    "#     yaxis_title=\"Tormenta\",\n",
    "#     yaxis=dict(\n",
    "#         tickmode='array',\n",
    "#         tickvals=list(range(len(storms_data)))\n",
    "#     ),\n",
    "#     showlegend=False,\n",
    "#     xaxis=dict(\n",
    "#         rangeslider=dict(\n",
    "#             visible=True\n",
    "#         ),\n",
    "#         type=\"date\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Mostrar la figura\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ABxa-pMvUiR"
   },
   "source": [
    "Mapa de calor de la matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831634958,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "ttbLXb7UvWm0"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 8))\n",
    "# sns.heatmap(hd.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-5Cz91Ap3RH"
   },
   "source": [
    "## 1.3 Limpieza y procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4RKW9php63d"
   },
   "source": [
    "### 1.3.1 Tratamiento de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1719831635295,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "t7usCL6U8a6U",
    "outputId": "88e0a147-1ef4-402f-815d-fa0902645794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42472"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hd.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831635295,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "FBM6gfRL85Tb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raqga\\AppData\\Local\\Temp\\ipykernel_15176\\2672241348.py:80: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\raqga\\AppData\\Local\\Temp\\ipykernel_15176\\2672241348.py:81: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "hd = imputar_nan(hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1719831635295,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "AwfFb2yZ8-dU",
    "outputId": "ff1eb87e-72e3-4471-f1ce-66cf42dfb9de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hd.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yn3SwS3Np93N"
   },
   "source": [
    "### 1.3.2 Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1719831635719,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "tSl0lkmfrHEz"
   },
   "outputs": [],
   "source": [
    "all_storms = filter_storms(hd, historical_storms, temporal_margin)\n",
    "all_storms = combinar_dataframes_solapados(all_storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1719831636440,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "z9Fj84tVSCwr"
   },
   "outputs": [],
   "source": [
    "pd.concat(all_storms).to_csv(tfm_path+\"all_storms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831636441,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "duerUHXhIFa5"
   },
   "outputs": [],
   "source": [
    "storms_check = pd.concat(all_storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1719831636910,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "dWxN6o_sIFsf"
   },
   "outputs": [],
   "source": [
    "all_storms, scaler_target = scale_data(all_storms, cols_to_use, col_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSZtUWlLqCAU"
   },
   "source": [
    "### 1.3.3 Codificación de variables categóricas\n",
    "\n",
    "* No existe codificación de variables categóricas porque **no hay variables categóricas). A continuación, se muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1719831636910,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "Xwu8MOV3qb2D",
    "outputId": "1c915010-c71d-4b57-fd1b-087a0e97668e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_IMF                  float64\n",
       "ID_plasma               float64\n",
       "Bmag                    float64\n",
       "dev_Bmag                float64\n",
       "Bx                      float64\n",
       "By_gse                  float64\n",
       "Bz_gse                  float64\n",
       "By_gsm                  float64\n",
       "Bz_gsm                  float64\n",
       "dev_Bx                  float64\n",
       "dev_By                  float64\n",
       "dev_Bz                  float64\n",
       "P_density               float64\n",
       "dev_P_density           float64\n",
       "AP                      float64\n",
       "dev_AP                  float64\n",
       "E_field                 float64\n",
       "plasma_T                float64\n",
       "dev_plasma_T            float64\n",
       "plasma_V                float64\n",
       "Dst                     float64\n",
       "Datetime         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(all_storms).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULHHGwCjqr6C"
   },
   "source": [
    "# 3 Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zqWtTvA4Ycl"
   },
   "source": [
    "## 3.1 Creación de la ventana temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "executionInfo": {
     "elapsed": 19565,
     "status": "ok",
     "timestamp": 1719831656473,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "XAm8sTsD4WrQ"
   },
   "outputs": [],
   "source": [
    "# x_window, y_window = create_window_df_svr(all_storms, lookforward, cols_to_use, col_to_predict, scaler_target) # desescalado\n",
    "x_window, y_window = create_window_df_svr(all_storms, lookback, lookforward, cols_to_use, col_to_predict) # sin desescalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWNESFbg5L_C"
   },
   "source": [
    "## 3.2 División en train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1719831656474,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "GIqtYB085ONF"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_window, y_window, test_size=test_size, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # Transforma a (n_samples, n_features*lookback)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)  # Lo mismo para el conjunto de prueba\n",
    "#X_train = np.squeeze(X_train, axis=1)\n",
    "#X_test = np.squeeze(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2EUAcFYM2ez"
   },
   "source": [
    "## 4 Optimización de la selección de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1719831656474,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "9xV7WmtdM5p2"
   },
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     # Suggesting hyperparameters using suggest_float\n",
    "#     C = trial.suggest_float('C', 1e-6, 1e2, log=True)  # Logarithmic for C\n",
    "#     gamma = trial.suggest_float('gamma', 1e-6, 1e2, log=True)  # Logarithmic for gamma\n",
    "#     epsilon = trial.suggest_float('epsilon', 0.001, 0.1)  # Linear for epsilon\n",
    "#     degree = trial.suggest_int('degree', 1, 10)  # Linear for epsilon\n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "\n",
    "#     # Create and train the SVR model from Thunder SVM\n",
    "#     model = SVR(C=C, gamma=gamma, epsilon=epsilon, degree=degree, kernel=kernel)\n",
    "\n",
    "#     # Evaluate the model using cross-validation\n",
    "#     score = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_squared_error').mean()\n",
    "#     return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the full path to the SQLite database\n",
    "# database_path = os.path.join(tfm_path+tfm_path_Nh_models, 'random_20240712-kaisa-non-linear_study.db')\n",
    "# storage_url = f'sqlite:///{database_path}'\n",
    "# new_study_name=\"random_kaisa-non-linear-study-20240712\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the study with the GridSampler\n",
    "# study = optuna.create_study(study_name=new_study_name,storage=storage_url, load_if_exists=True,sampler=optuna.samplers.RandomSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Ejecutar la optimización\n",
    "# study.optimize(objective, n_trials=100, timeout=600, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719831656474,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "DWN8j9R9B6AE"
   },
   "outputs": [],
   "source": [
    "# # Define the full path to the SQLite database\n",
    "# database_path = os.path.join(tfm_path+tfm_path_Nh_models, 'GRID_20240712-kaisa-linear_study.db')\n",
    "# storage_url = f'sqlite:///{database_path}'\n",
    "# new_study_name=\"GRID_kaisa-linear-study-20240712\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     C = trial.suggest_float('C', 1e-6, 1e2, log=True)\n",
    "#     gamma = trial.suggest_float('gamma', 1e-6, 1e2, log=True)\n",
    "#     epsilon = trial.suggest_float('epsilon', 0.001, 0.1)\n",
    "#     degree = trial.suggest_int('degree', 1, 10)\n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear'])\n",
    "\n",
    "#     # Create and train the model, evaluate using cross-validation\n",
    "#     model = SVR(C=C, gamma=gamma, epsilon=epsilon, degree=degree, kernel=kernel)\n",
    "#     score = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_squared_error').mean()\n",
    "#     return -score\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'C': np.logspace(-6, 2, num=6),  # Fewer points for demonstration\n",
    "#     'gamma': [1], # not used in linear\n",
    "#     'epsilon': np.linspace(0.001, 0.1, num=6),\n",
    "#     'degree': [1],  # Fixed for simplification, not used in linear\n",
    "#     'kernel': ['linear']  # Fixed to 'linear'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2842,
     "status": "ok",
     "timestamp": 1719831659312,
     "user": {
      "displayName": "Raquel G. Marañón",
      "userId": "10845715467248390754"
     },
     "user_tz": -120
    },
    "id": "qJbacq4uCMRH",
    "outputId": "adcf4538-767f-44a7-8a52-c7437c082d36"
   },
   "outputs": [],
   "source": [
    "# # Create the study with the GridSampler\n",
    "# study = optuna.create_study(study_name=new_study_name,storage=storage_url, load_if_exists=True,sampler=optuna.samplers.GridSampler(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "w1RcxiJOCXfb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study.optimize(objective, timeout=600, n_trials=len(param_grid['C']) * len(param_grid['gamma']) * len(param_grid['epsilon']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid for different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full path to the SQLite database\n",
    "database_path = os.path.join(tfm_path+tfm_path_Nh_models, f'DEF_kaisa_grid_allKernels_pred{lookforward}H_20240713.db')\n",
    "storage_url = f'sqlite:///{database_path}'\n",
    "new_study_name=f\"DEF_kaisa_grid_allKernels_pred{lookforward}_20240713\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-6, 2, num=6).tolist(),\n",
    "    'gamma': np.logspace(-6, 2, num=6).tolist(),\n",
    "    'epsilon': np.linspace(0.001, 0.1, num=6).tolist(),\n",
    "    'degree': list(range(1, 11)),\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_float('C', 1e-6, 1e2, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 0.001, 0.1)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        gamma = 1\n",
    "        degree = 1\n",
    "    elif kernel == 'poly':\n",
    "        gamma = 1\n",
    "        degree = trial.suggest_int('degree', 1, 10)\n",
    "    elif kernel == 'rbf':\n",
    "        gamma = trial.suggest_float('gamma', 1e-6, 1e2, log=True)\n",
    "        degree = 1\n",
    "\n",
    "    model = SVR(C=C, gamma=gamma, epsilon=epsilon, degree=degree, kernel=kernel, max_iter=1000000)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def print_metrics(study, trial):\n",
    "    print(f'Trial {trial.number}: Value={trial.value}, Params={trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 17:20:29,994] Using an existing study with name 'DEF_kaisa_grid_allKernels_pred2_20240713' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=new_study_name, storage=storage_url, load_if_exists=True, sampler=optuna.samplers.GridSampler(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS=len(param_grid['C']) * len(param_grid['epsilon']) * len(param_grid['kernel'])* len(param_grid['gamma'])\n",
    "print(NUM_TRIALS)\n",
    "\n",
    "## explicar por qué no se van a hacer de 648."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ-V-0cQqtmf"
   },
   "source": [
    "# 4 Evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "EP3W14kOjPpK"
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "P1PUpDA-j4lJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.06309573444801943, 'epsilon': 0.06040000000000001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "3A6BnhkAkyQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_C0.06309573444801943_eps0.06040000000000001_gammaNone_degNone finished. Time for iteration: 0 horas, 0 minutos, 27.63 segundos | mae: 0.09188013517199067 | mse: 0.027856915613331756 | exp_var: 0.9762694721879404 | max_err: 2.472118746354757\n"
     ]
    }
   ],
   "source": [
    "predictions, best_model_dict = evaluate_svr_models(X_train, y_train, X_test, y_test, [best_params['kernel']], [best_params['C']], [best_params['epsilon']], 1, 1, verbose=False)\n",
    "# , [best_params['gamma']], [best_params['degree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "1_8zaUoEkzQS"
   },
   "outputs": [],
   "source": [
    "best_model = best_model_dict[next(iter(best_model_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=0.06309573444801943, epsilon=0.06040000000000001, gamma=0.01,\n",
       "    kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVR<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVR(C=0.06309573444801943, epsilon=0.06040000000000001, gamma=0.01,\n",
       "    kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=0.06309573444801943, epsilon=0.06040000000000001, gamma=0.01,\n",
       "    kernel='linear')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "hB5bqIqhlF9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  | rmse: 70528.36907587184 |  mse: 4974250844.502397| mae: 50651.36493089173 | r2: -0.9101053517837259 | medae: 38534.48908957842 | explained_variance: 0.0014128643216082537 | max_err: 583408.4109175743\n",
      "Test  | rmse: 1975.9724013589707 |  mse: 3904466.9309323374| mae: 1391.5423610736248 | r2: -0.7497416168415294 | medae: 1047.2731511465815 | explained_variance: 0.051536839591778794 | max_err: 14044.804545032495\n"
     ]
    }
   ],
   "source": [
    "# Assume y_pred are the predictions from the model\n",
    "y_pred_scaled = best_model.predict(X_train)\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train = scaler_target.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Assume y_pred are the predictions from the model\n",
    "y_pred_scaledT = best_model.predict(X_test)\n",
    "y_pred_t = scaler_target.inverse_transform(y_pred_scaledT.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_target.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "mse, mae, r2, medae, exp_var, max_err = calc_metrics(y_pred, y_train)\n",
    "print(f\"Train  | rmse: {np.sqrt(mse)} |  mse: {mse}| mae: {mae} | r2: {r2} | medae: {medae} | explained_variance: {exp_var} | max_err: {max_err}\")\n",
    "mse, mae, r2, medae, exp_var, max_err = calc_metrics(y_pred_t, y_test)\n",
    "print(f\"Test  | rmse: {np.sqrt(mse)} |  mse: {mse}| mae: {mae} | r2: {r2} | medae: {medae} | explained_variance: {exp_var} | max_err: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[197], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_storms_train):\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), y_train[i], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y_pred[i])), y_pred[i], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicción del Modelo\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComparación de Predicción del Modelo con la Realidad para la Tormenta \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Entrenamiento)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Asumiendo que y_pred, y_train, y_pred_t y y_test son tuplas con arrays\n",
    "\n",
    "# Número de tormentas\n",
    "num_storms_train = len(y_pred)\n",
    "num_storms_test = len(y_pred_t)\n",
    "\n",
    "# Graficar cada tormenta para el conjunto de entrenamiento\n",
    "for i in range(num_storms_train):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(np.arange(len(y_train[i])), y_train[i], label='Real', marker='o')\n",
    "    plt.plot(np.arange(len(y_pred[i])), y_pred[i], label='Predicción del Modelo', marker='x')\n",
    "    plt.title(f'Comparación de Predicción del Modelo con la Realidad para la Tormenta {i} (Entrenamiento)')\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel('Dst (nT)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar cada tormenta para el conjunto de prueba\n",
    "for i in range(num_storms_test):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(np.arange(len(y_test[i])), y_test[i], label='Real', marker='o')\n",
    "    plt.plot(np.arange(len(y_pred_t[i])), y_pred_t[i], label='Predicción del Modelo', marker='x')\n",
    "    plt.title(f'Comparación de Predicción del Modelo con la Realidad para la Tormenta {i} (Prueba)')\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel('Dst (nT)')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
